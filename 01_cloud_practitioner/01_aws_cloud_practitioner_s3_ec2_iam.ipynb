{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19efa6d",
   "metadata": {},
   "source": [
    "# ‚òÅÔ∏è AWS Cloud Practitioner Essentials: S3, EC2, IAM\n",
    "\n",
    "**Generated:** 2025-09-22\n",
    "\n",
    "This notebook guides you through a focused, hands‚Äëon session covering **Amazon S3**, **Amazon EC2**, and **AWS IAM**. It‚Äôs designed for the AWS Cloud Practitioner level, with practical steps you can keep in your portfolio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc240e4e",
   "metadata": {},
   "source": [
    "## üéØ Objectives\n",
    "- Understand the purpose of **S3 (object storage)**, **EC2 (compute)**, and **IAM (identity & access)**.\n",
    "- Create and configure an **S3 bucket**, launch a **t2.micro EC2 instance**, and set basic **IAM** permissions.\n",
    "- Wire them together (EC2 ‚Üî S3 with IAM permissions) and document the workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec252992",
   "metadata": {},
   "source": [
    "## üîó Core Resources\n",
    "- **AWS Training ‚Äî Cloud Practitioner Essentials (free):** https://explore.skillbuilder.aws/learn/course/external/view/elearning/134/aws-cloud-practitioner-essentials\n",
    "- **Amazon S3 docs:** https://docs.aws.amazon.com/s3/index.html\n",
    "- **Amazon EC2 docs:** https://docs.aws.amazon.com/ec2/index.html\n",
    "- **AWS IAM docs:** https://docs.aws.amazon.com/iam/index.html\n",
    "- **AWS Free Tier:** https://aws.amazon.com/free/\n",
    "- **AWS CLI install:** https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712eb3e",
   "metadata": {},
   "source": [
    "## ‚úÖ Prerequisites\n",
    "- An AWS account (Free Tier eligible).\n",
    "- **AWS CLI** installed and configured (`aws configure`).  \n",
    "- A key pair for EC2 SSH (or be ready to create one in the console).\n",
    "- Basic terminal access (macOS/Linux Terminal, or Windows PowerShell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fdfb70",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) Amazon S3 ‚Äî Create and Configure a Bucket\n",
    "**Goal:** Create a bucket, upload a sample file, enable versioning, and explore storage classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e79bc",
   "metadata": {},
   "source": [
    "### Steps (Console)\n",
    "1. Go to the **S3 console** ‚Üí *Create bucket*.\n",
    "2. Choose a **globally unique** bucket name (e.g., `mlops-finance-elvin-<random>`), select a region, keep defaults (Block Public Access **ON**).\n",
    "3. **Create bucket**.\n",
    "4. Upload a small CSV (e.g., `prices.csv`) to the bucket.\n",
    "5. Enable **Versioning** in *Properties* and upload the file again to see versions.\n",
    "6. Explore **Storage class** options (e.g., Standard vs. Infrequent Access).\n",
    "\n",
    "> üì∏ **Insert screenshot(s) below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcadd6d4",
   "metadata": {},
   "source": [
    "![S3 Bucket Screenshot](../assets/s3_screenshot.png)\n",
    "\n",
    "### (Optional) Steps via AWS CLI\n",
    "```bash\n",
    "# create bucket (replace REGION and BUCKET)\n",
    "aws s3api create-bucket --bucket <YOUR_BUCKET> --region <REGION> --create-bucket-configuration LocationConstraint=<REGION>\n",
    "\n",
    "# enable versioning\n",
    "aws s3api put-bucket-versioning --bucket <YOUR_BUCKET> --versioning-configuration Status=Enabled\n",
    "\n",
    "# upload file\n",
    "aws s3 cp prices.csv s3://<YOUR_BUCKET>/data/prices.csv\n",
    "\n",
    "# list objects\n",
    "aws s3 ls s3://mlops-finance-data/data/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d313cb9",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Amazon EC2 ‚Äî Launch and Connect\n",
    "**Goal:** Launch a **t2.micro** (Free Tier) Amazon Linux instance and SSH into it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0681dcd",
   "metadata": {},
   "source": [
    "### Steps (Console)\n",
    "1. Go to **EC2 console** ‚Üí *Launch instance*.\n",
    "2. Name it: `mlops-finance-ec2`.\n",
    "3. AMI: **Amazon Linux 2023** (or Amazon Linux 2).\n",
    "4. Instance type: **t2.micro** (Free Tier eligible).\n",
    "5. Key pair: create or select an existing one.\n",
    "6. Security group: allow **SSH (22)** from *My IP*.\n",
    "7. Launch, wait for **running**, then copy the **Public IPv4 DNS**.\n",
    "8. SSH from your terminal:\n",
    "```bash\n",
    "chmod 400 <your-key>.pem\n",
    "ssh -i <your-key>.pem ec2-user@<EC2_PUBLIC_DNS>\n",
    "```\n",
    "9. On the instance, make sure Python is available (e.g., `python3 --version`).\n",
    "\n",
    "> üì∏ **Insert screenshot(s) below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b138f",
   "metadata": {},
   "source": [
    "![EC2 Instance Screenshot Placeholder](attachment:ec2_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfb01a",
   "metadata": {},
   "source": [
    "### (Optional) S3 from EC2\n",
    "If you attach an **IAM role** with S3 permissions to the instance, you can:\n",
    "```bash\n",
    "# On EC2 (Amazon Linux), install aws cli v2 if not present\n",
    "sudo dnf install -y awscli\n",
    "\n",
    "# Copy a file to S3 (no access keys needed when instance role is attached)\n",
    "echo \"hello\" > hello.txt\n",
    "aws s3 cp hello.txt s3://<YOUR_BUCKET>/hello.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeff460",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) AWS IAM ‚Äî Users, Policies, Roles\n",
    "**Goal:** Create a **read‚Äëonly S3 user**, generate access keys (for local CLI), and create an **instance role** for EC2 to access S3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7513adf",
   "metadata": {},
   "source": [
    "### Steps (Console)\n",
    "**User (Read‚Äëonly S3):**\n",
    "1. IAM console ‚Üí *Users* ‚Üí *Create user* ‚Üí `s3-readonly-user`.\n",
    "2. *Attach policies directly* ‚Üí add `AmazonS3ReadOnlyAccess`.\n",
    "3. Create **access key** (programmatic). Store them securely.\n",
    "\n",
    "**Instance Role (EC2 ‚Üî S3):**\n",
    "1. IAM console ‚Üí *Roles* ‚Üí *Create role* ‚Üí **Trusted entity: EC2**.\n",
    "2. Attach policy `AmazonS3FullAccess` (or least-privilege custom policy for your bucket).\n",
    "3. Name it `ec2-s3-access-role` and create.\n",
    "4. Go to EC2 instance ‚Üí *Actions* ‚Üí *Security* ‚Üí *Modify IAM role* ‚Üí attach `ec2-s3-access-role`.\n",
    "\n",
    "> üì∏ **Insert screenshot(s) below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891e53c",
   "metadata": {},
   "source": [
    "![IAM Screenshot Placeholder](attachment:iam_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd2dafa",
   "metadata": {},
   "source": [
    "### (Optional) Verify permissions\n",
    "```bash\n",
    "# Locally with read‚Äëonly user (after aws configure)\n",
    "aws s3 ls\n",
    "aws s3 cp somefile.txt s3://<YOUR_BUCKET>/   # expected to FAIL (read-only)\n",
    "\n",
    "# On EC2 with instance role\n",
    "aws s3 cp hello.txt s3://<YOUR_BUCKET>/      # expected to SUCCEED\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0bc1de",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Wire It Together ‚Äî Mini Flow\n",
    "**Scenario:** You generate a CSV of model outputs on EC2 and push it to S3 with the EC2 instance role.\n",
    "\n",
    "```bash\n",
    "# On EC2\n",
    "python3 - << 'PY'\n",
    "import csv, random\n",
    "from datetime import date\n",
    "rows = [('date','risk_score')]\n",
    "for i in range(5):\n",
    "    rows.append((str(date.today()), round(random.random(), 4)))\n",
    "with open('risk_scores.csv','w') as f:\n",
    "    csv.writer(f).writerows(rows)\n",
    "print(\"wrote risk_scores.csv\")\n",
    "PY\n",
    "\n",
    "aws s3 cp risk_scores.csv s3://<YOUR_BUCKET>/exports/risk_scores.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76da61c",
   "metadata": {},
   "source": [
    "## üîí Security Best Practices (Quick)\n",
    "- Prefer **IAM roles** over long‚Äëlived access keys on servers.\n",
    "- Keep **S3 buckets private**; use signed URLs or CloudFront if public access is needed.\n",
    "- Follow **least privilege**: restrict policies to specific buckets/paths.\n",
    "- Rotate credentials; never commit keys to GitHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429c6a7",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Reflection (fill in)\n",
    "- What did S3, EC2, and IAM each contribute to this workflow?\n",
    "- Where would you enforce least privilege?\n",
    "- How would you integrate this into an **MLOps** pipeline (e.g., training artifacts ‚Üí S3, batch inference on EC2/Lambda)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bd3fb",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] S3 bucket created, versioning enabled, file uploaded\n",
    "- [ ] EC2 instance launched and accessible via SSH\n",
    "- [ ] IAM user with S3 read‚Äëonly tested from local CLI\n",
    "- [ ] IAM role attached to EC2 and S3 upload verified\n",
    "- [ ] Mini flow (CSV ‚Üí S3) completed\n",
    "- [ ] Screenshots added to this notebook\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
